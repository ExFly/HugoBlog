---
title: "技术变革"
author: "exfly"
cover: "/media/img/architecture/kubernetes-logo.svg"
tags: ["bigdata", "总结"]
date: 2018-10-25T17:07:58+08:00
---

总结一下数据库、分布式等技术产生的场景的使用场景。包括数据库、缓存、分布式、容器

<!--more-->

从使用到的技术来说，如今各大网站平台趋向于使用经过长期检验过的技术，包括不限于动态网站技术、数据库技术、高速缓存技术、负载均衡、分布式相关技术。

首先**动态网站技术**，开始没有动态网站时期，大部分 BBS 使用基于 Telnet 协议为基础的 BBS 进行交流。HTTP 协议的出现，使得 BS 架构的网站能够展现多媒体等信息如视频、音乐等。起初 HTTP 协议一般仅展示一些静态数据，其表现能力不强，不能更好的动态的为用户交互。之后动态网站技术如 CGI 的出现，使得网站拥有的更加丰富的交互功能。经过数十年的技术积累，动态网站技术已经能够支撑起现如今的大部分信息的获取。

其次是**存储技术**。开始的时候数据仅仅使用本地文件进行存储。文件的读写效率很高，但是需要程序员重复的使用操作系统提供的较底层的操作来操作文件，对程序员的要求太大。而且对这种结构化的数据来说，可以使用相同的模式进行操作。所以有了数据库关系系统，尤其关系型数据库。从此，对于一些结构化的数据只需要使用 SQL 这种数据操作语言，就可以很方便的操作数据，而真正的数据管理维护工作由数据库管理系统进行维护，人可以通过配置数据库，使数据库获得更好的性能。当用户量很大时候，单机响应出现瓶颈，单台数据库不能够满足这样的请求。可以通过复制的方式，将相同的数据复制到多台机器上，多台机器为用户提供数据，对于读操作进行扩展。对于读多写少的网站，这种方式基本可以实现线性的性能提升。数据量再大一些，使用分库分表方式，把一份数据切片，分布到多台机器上提高性能。进而使用复制与分库分表的方式，进一步压榨单机的性能潜力。单机数据库很强大，但数据量达到一定的数量级，数据库的性能完全不能满足需求。大数据时代，数据量达到 PB、TB 级别。而每一块硬盘仅仅几 T，单机完全不可能将所有的数据都存储下来。如上分库分表的方式基本已经不能完全解决如上的问题，所以出现了分布式数据库，比如 MySQL Cluster 等通过两阶段提交等方式，维护线上数据的强一致性，分布式存储系统，比如 Google 研发的 GFS，现如今正火热的 HDFS 等，基本可以满足海量数据的存储。

高速**缓存技术**，如一些场景重复读的场景，数据库的查询很昂贵，如何减少数据库的访问次数？使用类似 Redis 的缓存。redis 的数据全部存储在内存中，内存的速度远远超过数据库的查询速度。维护 redis 中的缓存数据一致性，防止缓存穿透、缓存击穿、缓存雪崩的问题，以及如何正确的使用缓存等一系列问题，现如今已经基本有了很好的解决办法。

**负载均衡**与**反向代理**，传统中使用 nginx 作为网关，接受的请求分发到多台服务器中，一定程度上分担单台服务器的压力。

对于**分布式技术**。首先是 Google 研发并使用的 GFS 以及搭建在 GFS 基础上的 BigTable，以及 MapReduce 算法，使得分布式存储与分布式计算成为了可能。对应的开源版本为 HDFS、Hadoop、Spark 等一系列分布式基础设施。存储的分布式，也对应着应用部署的分布式，也就是现如今使用比较广泛的微服务（将一个整体的应用拆分成不同的服务，服务之间分别开发和部署，通过统一的接口进行协作）。微服务部署少则几个，多则成百上千，如此多的服务需要开发部署工作量巨大。同时很常见的问题是开发环境可以正常工作，上线却无法工作。这个问题现如今的解决办法是使用 docker。首先 docker 是一种使用 Linux 内核提供的 cgroup 和 namespace 功能，它可以将计算机的资源进行隔离。使用场景是通过容器编排工具，将服务所依赖的资源通过配置文件进行定义，由编排工具统一对所有的服务进行启动部署。现如今实质上的容器编排标准 Kubernetes，已经被不限于 Google、百度、阿里巴巴、京东等使用。对于 Google 等基本实现容器化、Kubernetes 化。
